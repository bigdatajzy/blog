---
title: tensorflow 学习资料整理（2）
date: 2018-09-06 10:03:00
categories:
- 人工智能/tensorflow
tags: 人工智能
---
简单整理一下从慕课上面学习的tensorflow的知识点，供大家一起学习讨论。

一、神经网络的参数
===============

神经网络的参数：是指神经元线上的权重w，用变量表示，一般会先随机生成这些参数。生成参数的方法是让w等于tf.Variable,把生成的方法写在括号里。

神经网络中常用的生成随机数/数组函数有：

tf.random_normal()        生成正态分布随机数

tf.truncated_normal()     生成去掉过大偏离点的正态分布随机数

tf.random_uniform()       生成均匀分布随机数

tf.zeros                  表示生成全0数组

tf.ones                   表示生成全1数组

tf.fill                   表示生成全定值数组

tf.constant               表示生成直接给定的数组

举例

1⃣️ w=tf.Variable(tf.random_normal([2.3],stddev=2,mean=0,seed=1)),表示生成正态分布随机数，形状两行三列，标准差是2，均值是0，随机种子是1。

2⃣️ w=tf.Variable(tf.Truncated_normal([2,3],stddev=2,mean=0,seed=1)),表示去掉偏离过大的正态分布，也就是如果随机出来的数值偏离平均值超过两个标准差，这个数据将重新生成。

3⃣️ w=random_uniform(shape=7,minval=0,maxval=1,dtype=tf.int32,seed=1),表示从一个均匀分布[minval.maxval)中随机采样，注意定义域是左闭右开，即包含minval，不包含maxval。

4⃣️ 除了生成随机数，还可以生成常量。tf.zeros([3,2],int32)表示生成[[1,1],[1,1],[1,1]];tf.fill([3,2],6)表示生成[[6,6],[6,6],[6,6]];tf.constant([3,2,1])表示生成[3,2,1]。

注意：1⃣️随机种子如果去掉的话每次生成的随机数将不一致。
2⃣️如果没有特殊要求标准差、均值、随机种子是可以不写的。

二、神经网络的搭建
===============

当我们知道张量、计算图、会话和参数后，我们可以讨论神经网络的实现过程了。

神经网络的实现过程：

1、准备数据集，提取特征，作为输入喂给神经网络（Neural Network，NN）

2、搭建NN结构，从输入到输出（先搭建计算图，再用会话执行）
（NN前向传播算法==>计算输出）

3、大量特征数据喂给NN，迭代优化NN参数
（NN反向传播算法==>优化参数训练模型）

4、使用训练好的模型预测和分类

由此可见，基于神经网络的机器学习主要分为两个过程，即训练过程和使用过程。训练过程是第一步、第二步、第三步的循环迭代，使用过程是第四步，一旦参数优化完成就可以固定这些参数，实现特定的应用了。

很多实际应用中，我们会先使用现有的成熟的网络结构，喂入新的数据，训练相应模型，判断是否能对喂入的从未见过的新数据作出正确响应，在适当更改网络结构，反复迭代，让机器自动训练参数找出最优结构和参数，以固定专用模型。



>文章来源于tensorflow笔记
