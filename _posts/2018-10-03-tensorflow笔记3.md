---
title: tensorflow 学习资料整理（3）
date: 2018-10-03 10:00:00
categories:
- 人工智能/tensorflow
tags: 人工智能
---
简单整理一下从慕课上面学习的tensorflow的知识点，供大家一起学习讨论。

三、前向传播
===============

前向传播就是搭建神经网络模型的计算过程，让模型具有一定的推理能力，可以针对一组输入给出相应的输出。
=================================================================================

举例

假如生产一批零件，体积为x1，重量为x2，体积和重量就是我们选择的特征，把它喂入神经网络，当体积和重量这组数据走过神经网络后会得到一个输出。

假如输入特征为：体积0.7 重量0.5

假设我们用上一个神经网络模型：两层的神经网络，一个隐藏层，共3个节点。

第一层权重：W1.1 = 0.2、W2.1 = 0.3、W1.2 = 0.1、W2.2 = 0.5、W1.3 = 0.4、W2.3 = 0.2

第二层权重：W1.1 = 0.1、W2.2 = 0.1、W3.1 = -0.2

由搭建的神经网络可得：

隐藏层节点：a11 = x1 * W11 + x2 * W21 = 0.29 同理可得 a12 = 0.32 、a13 = 0.38，最终计算得到的Y的输出值为Y = -0.015这便实现了前向传播的过程。

推导：
=====

第一层
======

x是输入为1*2的矩阵

用x表示输入，是一个一行两列的矩阵，表示一次输入一组特征，这组特征包含了体积和重量两种元素。

W（前节点编号，后节点编号）（层数） 为待优化参数

神经网络共有几层（或当前是第几层网络）都是指的是计算层，输入不是计算层，所以a为第一层网络，a是一个一行三列的矩阵。

我们这样表示 a（1） = [a11,a12,a13] = XW(1)

第二层
======

参数要满足前面的三个节点，后面一个节点，所以W是一行三列的矩阵。

我们把每次输入乘以线上的权重W，这样用矩阵乘法可以计算出输出Y了。

a = tf.matmul(X,W1)

y = tf.matmul(a,W2)

由于需要计算结果，就要用with结构实现，所有变量初始化过程，计算过程都要放到sess.run函数中，对于变量初始化，我们在sess.run中写入tf.global_varables_initiaizer实现对所有变量初始化，也就是赋值。对于计算图中的运算，我们直接把运算节点填入sess.run即可比如要计算输出Y，直接写sess.run(Y)即可。

实际应用中，我们可以一次喂入一组或多组输入，让神经网络计算输出Y，可以先用tf.placeholder给输入占位，如果一次喂一组数据shape的第一维位置写1，第二维位置看有几个输入特征；如果一次想喂入多组数据，shape的位置可以先写None空着，第二维位置写有几个输入特征，这样在feed_dict中可以喂入若干组体积重量了。


>文章来源于tensorflow笔记
